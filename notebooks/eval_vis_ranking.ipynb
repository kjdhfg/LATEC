{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path(os.getcwd()).parents[0])\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import sem\n",
    "\n",
    "from src.utils.plot_utils import *\n",
    "\n",
    "\n",
    "def NormalizeData(data, min, max):\n",
    "    return (data - min) / ((max - min) + 0.00000000001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Evaluation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File loading per dataset\n",
    "\n",
    "file_image_inet = \"/image/eval_scores_imagenet.npz\"\n",
    "file_image_oct = \"/image/eval_scores_oct.npz\"\n",
    "file_image_r45 = \"/image/eval_scores_resisc45.npz\"\n",
    "\n",
    "file_volume_adr = \"/volume/eval_scores_adrenalmnist3d.npz\"\n",
    "file_volume_org = \"/volume/eval_scores_organmnist3d.npz\"\n",
    "file_volume_ves = \"/volume/eval_scores_vesselmnist3d.npz\"\n",
    "\n",
    "file_pc_coma = \"/point_cloud/eval_scores_coma.npz\"\n",
    "file_pc_m40 = \"/point_cloud/eval_scores_modelnet40.npz\"\n",
    "file_pc_shpn = \"/point_cloud/eval_scores_shapenet.npz\"\n",
    "\n",
    "file_loc = os.getcwd() + \"/data/evaluation_scores\"\n",
    "\n",
    "file = np.load(file_loc + file_image_inet, allow_pickle=True)\n",
    "arr_image_inet = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_image_oct, allow_pickle=True)\n",
    "arr_image_oct = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_image_r45, allow_pickle=True)\n",
    "arr_image_r45 = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "\n",
    "file = np.load(file_loc + file_volume_adr, allow_pickle=True)\n",
    "arr_volume_adr = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_volume_org, allow_pickle=True)\n",
    "arr_volume_org = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_volume_ves, allow_pickle=True)\n",
    "arr_volume_ves = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "\n",
    "file = np.load(file_loc + file_pc_coma, allow_pickle=True)\n",
    "arr_pc_coma = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_pc_m40, allow_pickle=True)\n",
    "arr_pc_m40 = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]\n",
    "file = np.load(file_loc + file_pc_shpn, allow_pickle=True)\n",
    "arr_pc_shpn = [file[\"arr_0\"], file[\"arr_1\"], file[\"arr_2\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "\n",
    "data = arr_pc_shpn\n",
    "\n",
    "titles = [\n",
    "    \"<b>[F]</b> Faithfulness Correlation \\u2191\",\n",
    "    \"[F] Faithfulness Estimate \\u2191\",\n",
    "    \"[F] Monotonicity Correlation \\u2191\",\n",
    "    \"[F] Pixel Flipping (AUC) \\u2193\",\n",
    "    \"[F] Region Perturbation (AUC) \\u2191\",\n",
    "    \"[F] Insertion \\u2191\",\n",
    "    \"[F] Deletion \\u2193\",\n",
    "    \"[F] IROF (AOC) \\u2191\",\n",
    "    \"[F] ROAD (AUC) \\u2193\",\n",
    "    \"[F] Sufficiency \\u2191\",\n",
    "    \"[F] Infidelity \\u2193\",\n",
    "    \"<b>[R]</b> Local Lipschitz Estimate \\u2193\",\n",
    "    \"[R] Max Sensitivity \\u2193\",\n",
    "    \"[R] Continuity (PCC) \\u2191\",\n",
    "    \"[R] Relative Input Stability \\u2193\",\n",
    "    \"[R] Relative Output Stability \\u2193\",\n",
    "    \"[R] Relative Repr. Stability \\u2193\",\n",
    "    \"<b>[C]</b> Sparseness \\u2191\",\n",
    "    \"[C] Complexity \\u2193\",\n",
    "    \"[C] Effective Complexity \\u2193\",\n",
    "]\n",
    "\n",
    "methods = (\n",
    "    [\n",
    "        \"OC\",\n",
    "        \"LI\",\n",
    "        \"KS\",\n",
    "        \"SA\",\n",
    "        \"IxG\",\n",
    "        \"GB\",\n",
    "        \"GC\",\n",
    "        \"SC\",\n",
    "        \"C+\",\n",
    "        \"IG\",\n",
    "        \"EG\",\n",
    "        \"DL\",\n",
    "        \"DLS\",\n",
    "        \"LRP\",\n",
    "        \"RA\",\n",
    "        \"RoA\",\n",
    "        \"LA\",\n",
    "    ]\n",
    "    if data[0].shape[0] >= 14\n",
    "    else [\n",
    "        \"OC\",\n",
    "        \"LI\",\n",
    "        \"KS\",\n",
    "        \"SA\",\n",
    "        \"IxG\",\n",
    "        \"GB\",\n",
    "        \"IG\",\n",
    "        \"EG\",\n",
    "        \"DL\",\n",
    "        \"DLS\",\n",
    "        \"LRP\",\n",
    "        \"RA\",\n",
    "        \"RoA\",\n",
    "        \"LA\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=5,\n",
    "    cols=4,\n",
    "    vertical_spacing=0.05,\n",
    "    horizontal_spacing=0.03,\n",
    "    subplot_titles=titles,\n",
    ")\n",
    "\n",
    "plot_row = [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5]\n",
    "plot_col = [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]\n",
    "plot_x = (\n",
    "    [\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"atten\",\n",
    "        \"atten\",\n",
    "        \"atten\",\n",
    "    ]\n",
    "    if data[0].shape[1] == 20\n",
    "    else [\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"attr\",\n",
    "        \"atten\",\n",
    "        \"atten\",\n",
    "        \"atten\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i in range(20):  # per eval\n",
    "    d = np.vstack(\n",
    "        [\n",
    "            data[0][:, i, :],\n",
    "            data[1][:, i, :],\n",
    "            data[2][(data[2].shape[0] - 3) : data[2].shape[0], i, :],\n",
    "        ]\n",
    "    ).flatten()\n",
    "    q_h = np.quantile(d, 0.9)\n",
    "    q_l = np.quantile(d, 0.1)\n",
    "    d = np.clip(d, q_l, q_h)\n",
    "    d_max = d.max()\n",
    "    d_min = d.min()\n",
    "\n",
    "    data[0][:, i, :] = NormalizeData(np.clip(data[0][:, i, :], q_l, q_h), d_min, d_max)\n",
    "    data[1][:, i, :] = NormalizeData(np.clip(data[1][:, i, :], q_l, q_h), d_min, d_max)\n",
    "    data[2][(data[2].shape[0] - 3) : data[2].shape[0], i, :] = NormalizeData(\n",
    "        np.clip(data[2][(data[2].shape[0] - 3) : data[2].shape[0], i, :], q_l, q_h),\n",
    "        d_min,\n",
    "        d_max,\n",
    "    )\n",
    "\n",
    "    for j in range(data[0].shape[0]):  # per attribution\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=np.concatenate((data[0][j, i, :], data[1][j, i, :])),\n",
    "                name=methods[j],\n",
    "                marker_color=colors[0],\n",
    "                showlegend=False,\n",
    "            ),  # model, explain, eval, n\n",
    "            row=plot_row[i],\n",
    "            col=plot_col[i],\n",
    "        )\n",
    "    for j in range(data[2].shape[0] - 3, data[2].shape[0]):  # per attention\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=data[2][j, i, :],\n",
    "                name=methods[j],\n",
    "                marker_color=colors[2],\n",
    "                showlegend=False,\n",
    "            ),  # model, explain, eval, n\n",
    "            row=plot_row[i],\n",
    "            col=plot_col[i],\n",
    "        )\n",
    "\n",
    "    fig.add_hline(\n",
    "        y=np.median(np.concatenate((data[0][:, i, :], data[1][:, i, :]))),\n",
    "        x0=0,\n",
    "        x1=(1 / 17) * 14,\n",
    "        line_dash=\"dot\",\n",
    "        row=plot_row[i],\n",
    "        col=plot_col[i],\n",
    "        line_color=\"#000000\",\n",
    "        line_width=2,\n",
    "    )\n",
    "    fig.add_hline(\n",
    "        y=np.median(data[2][(data[2].shape[0] - 3) : data[2].shape[0], i, :]),\n",
    "        x0=(1 / 17) * 14,\n",
    "        x1=1,\n",
    "        line_dash=\"dot\",\n",
    "        row=plot_row[i],\n",
    "        col=plot_col[i],\n",
    "        line_color=\"#000000\",\n",
    "        line_width=2,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=2000,\n",
    "    margin=dict(t=60, b=10, r=10, l=10),\n",
    "    font=dict(\n",
    "        family=\"Helvetica\",\n",
    "        color=\"#000000\",\n",
    "    ),\n",
    "    title_font=dict(\n",
    "        family=\"Helvetica\",\n",
    "        color=\"#000000\",\n",
    "    ),\n",
    "    title={\n",
    "        \"text\": \"Evaluation Score Distributions for ShapeNet Dataset per XAI Method and grouped into Attribution and Attention\",\n",
    "        # 'y':0.9,\n",
    "        \"x\": 0.012,\n",
    "    },\n",
    ")\n",
    "\n",
    "fig = left_align_facet_plot_titles(fig)\n",
    "fig.update_annotations(font_size=12)\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/eval_distr/shapenet.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Ranking\n",
    "arr_image = [arr_image_inet, arr_image_oct, arr_image_r45]\n",
    "arr_volume = [arr_volume_adr, arr_volume_org, arr_volume_ves]\n",
    "arr_pc = [arr_pc_coma, arr_pc_m40, arr_pc_shpn]\n",
    "arr_modalities = [arr_image, arr_volume, arr_pc]\n",
    "\n",
    "arr_ranking = np.empty(\n",
    "    [3, 3, 3, 17, 20], dtype=float\n",
    ")  # modality, dataset, model, xai, eval\n",
    "arr_ranking[:] = np.nan\n",
    "\n",
    "bup_order = [0, 1, 2, 4, 5, 7, 9, 12, 17]\n",
    "\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for model in range(3):\n",
    "            for xai in range(arr_modalities[modality][dataset][model].shape[0]):\n",
    "                for eval in range(20):\n",
    "                    ranking = np.median(\n",
    "                        arr_modalities[modality][dataset][model][:, eval, :], -1\n",
    "                    ).argsort()  # compute ranking based on median obs score\n",
    "                    if eval in bup_order:\n",
    "                        ranking = ranking[\n",
    "                            ::-1\n",
    "                        ]  # reverse ranking to bottom up if larger is better\n",
    "\n",
    "                    pos = (\n",
    "                        ranking.argsort()[xai] + 1\n",
    "                    )  # get rankin position of xai method (+1 so ranking starts at 1 and not 0)\n",
    "                    arr_ranking[modality, dataset, model, xai, eval] = pos\n",
    "\n",
    "arr_table = []\n",
    "for eval in range(20):\n",
    "    for modality in range(3):\n",
    "        for dataset in range(3):\n",
    "            arr_col_val = []\n",
    "            for model in [2]:\n",
    "                for xai in range(17):\n",
    "                    if modality == 2 and xai == 6:\n",
    "                        arr_col_val = arr_col_val + [\n",
    "                            np.round(np.mean(arr_ranking[(0, 1), :, :, 6, eval])),\n",
    "                            np.round(np.mean(arr_ranking[(0, 1), :, :, 7, eval])),\n",
    "                            np.round(np.mean(arr_ranking[(0, 1), :, :, 8, eval])),\n",
    "                        ]\n",
    "                    if modality == 2 and xai == 11:\n",
    "                        break\n",
    "                    x = arr_ranking[modality, dataset, model, xai, eval]\n",
    "                    val = np.round(np.mean(x[~np.isnan(x)]))\n",
    "                    arr_col_val.append(val)\n",
    "                arr_table.append(arr_col_val)\n",
    "\n",
    "df_table = pd.DataFrame(arr_table).transpose()\n",
    "df_table.index = [\n",
    "    \"OC\",\n",
    "    \"LIME\",\n",
    "    \"KS\",\n",
    "    \"VG\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "    \"RA\",\n",
    "    \"RoA\",\n",
    "    \"LA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking accross models and datasets\n",
    "arr_image = [arr_image_inet, arr_image_oct, arr_image_r45]\n",
    "arr_volume = [arr_volume_adr, arr_volume_org, arr_volume_ves]\n",
    "arr_pc = [arr_pc_coma, arr_pc_m40, arr_pc_shpn]\n",
    "arr_modalities = [arr_image, arr_volume, arr_pc]\n",
    "\n",
    "arr_ranking = np.empty([3, 17, 20], dtype=float)  # modality, dataset, xai, eval\n",
    "arr_ranking[:] = np.nan\n",
    "\n",
    "bup_order = [0, 1, 2, 4, 5, 7, 9, 12, 17]\n",
    "\n",
    "for modality in range(3):\n",
    "    for eval in range(20):\n",
    "        arr_scores = []\n",
    "        for model in range(3):\n",
    "            for data in range(3):\n",
    "                d = arr_modalities[modality][data][model][:, eval, :]\n",
    "                q_h = np.quantile(d, 0.975)\n",
    "                q_l = np.quantile(d, 0.025)\n",
    "\n",
    "                d = np.clip(d, q_l, q_h)\n",
    "                d_max = d.max()\n",
    "                d_min = d.min()\n",
    "                arr_scores.append(NormalizeData(d, d_min, d_max))\n",
    "\n",
    "        model_1 = np.column_stack(\n",
    "            (\n",
    "                np.median(arr_scores[0], 1),\n",
    "                np.median(arr_scores[1], 1),\n",
    "                np.median(arr_scores[2], 1),\n",
    "            )\n",
    "        )\n",
    "        model_2 = np.column_stack(\n",
    "            (\n",
    "                np.median(arr_scores[3], 1),\n",
    "                np.median(arr_scores[4], 1),\n",
    "                np.median(arr_scores[5], 1),\n",
    "            )\n",
    "        )\n",
    "        model_3 = np.column_stack(\n",
    "            (\n",
    "                np.median(arr_scores[6], 1),\n",
    "                np.median(arr_scores[7], 1),\n",
    "                np.median(arr_scores[8], 1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ranking = np.concatenate(\n",
    "            [\n",
    "                np.mean(\n",
    "                    np.hstack([model_1, model_2, model_3[:-3]]),\n",
    "                    -1,\n",
    "                ),\n",
    "                np.mean(model_3[-3:], -1),\n",
    "            ]\n",
    "        ).argsort()\n",
    "        # compute ranking based on median obs score\n",
    "        if eval in bup_order:\n",
    "            ranking = ranking[::-1]  # reverse ranking to bottom up if larger is better\n",
    "\n",
    "        for xai in range(ranking.shape[0]):\n",
    "            pos = (\n",
    "                ranking.argsort()[xai] + 1\n",
    "            )  # get rankin position of xai method (+1 so ranking starts at 1 and not 0)\n",
    "            arr_ranking[modality, xai, eval] = pos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Table as in Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_faith = arr_ranking[0, :, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16]].T.round(1)\n",
    "img_faith_table = np.column_stack(\n",
    "    (img_faith.mean(1).round(1), img_faith.std(1).round(1), img_faith)\n",
    ")\n",
    "np.savetxt(\"./img_faith.csv\", img_faith_table, delimiter=\",\")\n",
    "\n",
    "vol_faith = arr_ranking[1, :, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16]].T.round(1)\n",
    "vol_faith_table = np.column_stack(\n",
    "    (vol_faith.mean(1).round(1), vol_faith.std(1).round(1), vol_faith)\n",
    ")\n",
    "np.savetxt(\"./vol_faith.csv\", vol_faith_table, delimiter=\",\")\n",
    "\n",
    "pc_faith = arr_ranking[2, :, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16]].T.round(1)\n",
    "pc_faith_table = np.column_stack(\n",
    "    (pc_faith.mean(1).round(1), pc_faith.std(1).round(1), pc_faith)\n",
    ")\n",
    "np.savetxt(\"./pc_faith.csv\", pc_faith_table, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rob = arr_ranking[0, :, [10, 11, 12, 13, 14, 15]].T.round(1)\n",
    "img_rob_table = np.column_stack(\n",
    "    (img_rob.mean(1).round(1), img_rob.std(1).round(1), img_rob)\n",
    ")\n",
    "np.savetxt(\"./img_rob.csv\", img_rob_table, delimiter=\",\")\n",
    "\n",
    "vol_rob = arr_ranking[1, :, [10, 11, 12, 13, 14, 15]].T.round(1)\n",
    "vol_rob_table = np.column_stack(\n",
    "    (vol_rob.mean(1).round(1), vol_rob.std(1).round(1), vol_rob)\n",
    ")\n",
    "np.savetxt(\"./vol_rob.csv\", vol_rob_table, delimiter=\",\")\n",
    "\n",
    "pc_rob = arr_ranking[2, :, [10, 11, 12, 13, 14, 15]].T.round(1)\n",
    "pc_rob_table = np.column_stack(\n",
    "    (pc_rob.mean(1).round(1), pc_rob.std(1).round(1), pc_rob)\n",
    ")\n",
    "np.savetxt(\"./pc_rob.csv\", pc_rob_table, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_comp = arr_ranking[0, :, [17, 18, 19]].T.round(1)\n",
    "img_comp_table = np.column_stack(\n",
    "    (img_comp.mean(1).round(1), img_comp.std(1).round(1), img_comp)\n",
    ")\n",
    "np.savetxt(\"./img_comp.csv\", img_comp_table, delimiter=\",\")\n",
    "\n",
    "vol_comp = arr_ranking[1, :, [17, 18, 19]].T.round(1)\n",
    "vol_comp_table = np.column_stack(\n",
    "    (vol_comp.mean(1).round(1), vol_comp.std(1).round(1), vol_comp)\n",
    ")\n",
    "np.savetxt(\"./vol_comp.csv\", vol_comp_table, delimiter=\",\")\n",
    "\n",
    "pc_comp = arr_ranking[2, :, [17, 18, 19]].T.round(1)\n",
    "pc_comp_table = np.column_stack(\n",
    "    (pc_comp.mean(1).round(1), pc_comp.std(1).round(1), pc_comp)\n",
    ")\n",
    "np.savetxt(\"./pc_comp.csv\", pc_comp_table, delimiter=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_table = []\n",
    "for eval in [(0, 10), (10, 17), (17, 20)]:\n",
    "    for modality in range(3):\n",
    "        arr_col_val = []\n",
    "        arr_col_std = []\n",
    "        for xai in range(17):\n",
    "            if modality == 2 and xai == 6:\n",
    "                arr_col_val = arr_col_val + [\"-\", \"-\", \"-\"]\n",
    "                arr_col_std = arr_col_std + [np.nan, np.nan, np.nan]\n",
    "            if modality == 2 and xai == 14:\n",
    "                break\n",
    "            x = arr_ranking[modality, :, xai, eval[0] : eval[1]]\n",
    "            val = np.round(np.mean(x[~np.isnan(x)]))\n",
    "            std = np.round(np.std(x[~np.isnan(x)]), 2)\n",
    "            if not np.isnan(val):\n",
    "                val = int(val)\n",
    "            else:\n",
    "                val = \"-\"\n",
    "                std = \"-\"\n",
    "            arr_col_val.append(val)\n",
    "            # arr_col_std.append(std)\n",
    "        arr_table.append(arr_col_val)\n",
    "        # arr_table.append(arr_col_std)\n",
    "\n",
    "df_table = pd.DataFrame(arr_table).transpose()\n",
    "df_table.index = [\n",
    "    \"OC\",\n",
    "    \"LI\",\n",
    "    \"KS\",\n",
    "    \"VG\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "    \"RA\",\n",
    "    \"RoA\",\n",
    "    \"LA\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention vs. Attribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS, TSNE\n",
    "\n",
    "mds = MDS(n_components=2, random_state=4)\n",
    "# mds = TSNE(perplexity= 10)\n",
    "X_transformed = mds.fit_transform(df_table)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "X_transformed[4, 0] = X_transformed[4, 0] - 4\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_transformed[:-3, 0],\n",
    "        y=X_transformed[:-3, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=[\n",
    "            \"OC\",\n",
    "            \"LIME\",\n",
    "            \"KS\",\n",
    "            \"VG\",\n",
    "            \"IxG\",\n",
    "            \"GB\",\n",
    "            \"GC\",\n",
    "            \"SC\",\n",
    "            \"C+\",\n",
    "            \"IG\",\n",
    "            \"EG\",\n",
    "            \"DL\",\n",
    "            \"DLS\",\n",
    "            \"LRP\",\n",
    "        ],\n",
    "        textposition=\"top right\",\n",
    "        name=\"Attribution\",\n",
    "        marker=dict(color=colors[0], size=8),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_transformed[-3:, 0],\n",
    "        y=X_transformed[-3:, 1],\n",
    "        mode=\"markers+text\",\n",
    "        text=[\"RA\", \"RoA\", \"LA\"],\n",
    "        textposition=\"top right\",\n",
    "        name=\"Attention\",\n",
    "        marker=dict(color=colors[2], size=8),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    # range=[-60.5, 60.5], tickvals=[-60, -40, -20, 0, 20, 40, 60], zerolinewidth=3\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    # range=[-75.5, 75.5], tickvals=[-75, -50, -25, 0, 25, 50, 75], zerolinewidth=3\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=550,\n",
    "    xaxis=dict(\n",
    "        title=\"Dim 1\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Dim 2\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"XAI Methods\", font=dict(family=\"Helvetica\", size=16, color=\"#000000\")\n",
    "    ),\n",
    "    template=\"plotly_white\",\n",
    ")\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/mds_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg. Rank per XAI Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "x = [\n",
    "    [\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attribution\",\n",
    "        \"Attention\",\n",
    "        \"Attention\",\n",
    "        \"Attention\",\n",
    "    ],\n",
    "    [\n",
    "        \"OC\",\n",
    "        \"LI\",\n",
    "        \"KS\",\n",
    "        \"VG\",\n",
    "        \"IxG\",\n",
    "        \"GB\",\n",
    "        \"GC\",\n",
    "        \"SC\",\n",
    "        \"C+\",\n",
    "        \"IG\",\n",
    "        \"EG\",\n",
    "        \"DL\",\n",
    "        \"DLS\",\n",
    "        \"LRP\",\n",
    "        \"RA\",\n",
    "        \"RoA\",\n",
    "        \"LA\",\n",
    "    ],\n",
    "]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.mean(df_table.iloc[:, :90], axis=1), 1),\n",
    "        name=\"Faithfullness\",\n",
    "        marker_color=colors[0],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(df_table.iloc[:, :90], axis=1), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\", array=np.round(sem(df_table.iloc[:, :90], axis=1), 2)\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.mean(df_table.iloc[:, 90:153], axis=1), 1),\n",
    "        name=\"Robustness\",\n",
    "        marker_color=colors[4],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(df_table.iloc[:, 90:153], axis=1), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\", array=np.round(sem(df_table.iloc[:, 90:153], axis=1), 2)\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.mean(df_table.iloc[:, 153:180], axis=1), 1),\n",
    "        name=\"Complexity\",\n",
    "        marker_color=colors[5],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(df_table.iloc[:, 153:180], axis=1), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\", array=np.round(sem(df_table.iloc[:, 153:180], axis=1), 2)\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"Evaluation Criteria\",\n",
    "        font=dict(family=\"Helvetica\", size=16, color=\"#000000\"),\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=1500,\n",
    ")\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/aa_full_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "\n",
    "\n",
    "df_corr = np.corrcoef(df_table)\n",
    "mask = np.ones_like(df_corr, dtype=bool)\n",
    "mask[:] = np.nan\n",
    "mask = np.triu(mask).T\n",
    "\n",
    "\n",
    "heat = go.Heatmap(\n",
    "    z=df_corr * mask,\n",
    "    x=df_table.index,\n",
    "    y=df_table.index,\n",
    "    text=df_corr * mask,\n",
    "    zmin=-1,  # Sets the lower bound of the color domain\n",
    "    zmax=1,\n",
    "    xgap=1,  # Sets the horizontal gap (in pixels) between bricks\n",
    "    ygap=1,\n",
    "    colorscale=[\n",
    "        [0, \"#B5545C\"],\n",
    "        [0.1, \"#B5545C\"],\n",
    "        [0.5, \"rgb(245, 245, 245)\"],\n",
    "        [0.9, \"#76BB40\"],\n",
    "        [1, \"#76BB40\"],\n",
    "    ],\n",
    "    coloraxis_colorbar=dict(\n",
    "        thicknessmode=\"pixels\",\n",
    "        thickness=10,\n",
    "        lenmode=\"pixels\",\n",
    "        len=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    width=600,\n",
    "    height=600,\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False,\n",
    "    yaxis_autorange=\"reversed\",\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=16),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[heat], layout=layout)\n",
    "\n",
    "fig.write_image(os.getcwd().split(\"src\")[0] + \"data/figures/corr_total.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg rank per Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "x = [\n",
    "    \"OC\",\n",
    "    \"LI\",\n",
    "    \"KS\",\n",
    "    \"VG\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "]\n",
    "\n",
    "for model in range(3):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=x,\n",
    "            y=np.round(np.mean(arr_ranking[2, :, model, :14, :10], axis=(0, 2)), 1),\n",
    "            name=[\"CNN<sub>1</sub>\", \"CNN<sub>2</sub>\", \"Transformer\"][model],\n",
    "            marker_color=[colors[i] for i in [0, 5, 2]][model],\n",
    "            textposition=\"inside\",\n",
    "            insidetextanchor=\"start\",\n",
    "            text=np.round(np.mean(arr_ranking[2, :, model, :14, :10], axis=(0, 2)), 1),\n",
    "            error_y=dict(\n",
    "                type=\"data\",\n",
    "                array=[\n",
    "                    np.round(sem(arr_ranking[2, :, model, i, :10].flatten()), 2)\n",
    "                    for i in range(14)\n",
    "                ],\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=16),\n",
    "    legend_title=dict(\n",
    "        text=\"Model Architecture\",\n",
    "        font=dict(family=\"Helvetica\", size=16, color=\"#000000\"),\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=1500,\n",
    ")\n",
    "\n",
    "fig.write_image(\n",
    "    os.getcwd().split(\"src\")[0] + \"data/figures/bar_models_faith_vol.png\", scale=2\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg. Rank per Evaluation Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=[\"Faithfullness\", \"Robustness\", \"Complexity\"],\n",
    "        y=[\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, :90]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, 90:153]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, 153:180]), 1),\n",
    "        ],\n",
    "        name=\"Attribution\",\n",
    "        marker_color=colors[0],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=[\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, :90]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, 90:153]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[:-3, 153:180]), 1),\n",
    "        ],\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=[\n",
    "                sem(df_table.iloc[:-3, :90], axis=None),\n",
    "                sem(df_table.iloc[:-3, 90:153], axis=None),\n",
    "                sem(df_table.iloc[:-3, 153:180], axis=None),\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=[\"Faithfullness\", \"Robustness\", \"Complexity\"],\n",
    "        y=[\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, :90]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, 90:153]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, 153:180]), 1),\n",
    "        ],\n",
    "        name=\"Attention\",\n",
    "        marker_color=colors[2],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=[\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, :90]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, 90:153]), 1),\n",
    "            np.round(np.nanmean(df_table.iloc[-3:, 153:180]), 1),\n",
    "        ],\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=[\n",
    "                sem(df_table.iloc[15:, :90], axis=None),\n",
    "                sem(df_table.iloc[15:, 90:153], axis=None),\n",
    "                sem(df_table.iloc[15:, 153:180], axis=None),\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"Evaluation Criteria\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"XAI Methods\", font=dict(family=\"Helvetica\", size=16, color=\"#000000\")\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=700,\n",
    ")\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "t1 = stats.ttest_ind(\n",
    "    a=df_table.iloc[:-3, :90].to_numpy().flatten(),\n",
    "    b=df_table.iloc[-3:, :90].to_numpy().flatten(),\n",
    "    equal_var=False,\n",
    ")[1]\n",
    "t2 = stats.ttest_ind(\n",
    "    a=df_table.iloc[:-3, 90:153].to_numpy().flatten(),\n",
    "    b=df_table.iloc[-3:, 90:153].to_numpy().flatten(),\n",
    "    equal_var=False,\n",
    ")[1]\n",
    "t3 = stats.ttest_ind(\n",
    "    a=df_table.iloc[:-3, 153:180].to_numpy().flatten(),\n",
    "    b=df_table.iloc[-3:, 153:180].to_numpy().flatten(),\n",
    "    equal_var=False,\n",
    ")[1]\n",
    "\n",
    "for i in range(3):\n",
    "    fig = add_p_value_annotation(\n",
    "        fig,\n",
    "        array_columns=[[-0.25 + i, 0.25 + i]],\n",
    "        p_value=[[t1, t2, t3][i]],\n",
    "        _format=dict(interline=0.06, text_height=1.08, color=\"black\"),\n",
    "    )\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/aa_aggr_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modality Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_table = []\n",
    "for modality in range(3):\n",
    "    for eval in range(20):\n",
    "        for dataset in range(3):\n",
    "            arr_col_val = []\n",
    "            for xai in range(17):\n",
    "                if modality == 2 and xai == 6:\n",
    "                    arr_col_val = arr_col_val + [np.nan, np.nan, np.nan]\n",
    "                if modality == 2 and xai == 14:\n",
    "                    break\n",
    "                val = arr_ranking[modality, dataset, xai, eval]\n",
    "                arr_col_val.append(val)\n",
    "            arr_table.append(arr_col_val)\n",
    "\n",
    "df_table = pd.DataFrame(arr_table).transpose()\n",
    "df_table.index = [\n",
    "    \"OC\",\n",
    "    \"LI\",\n",
    "    \"KS\",\n",
    "    \"SA\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "    \"RA\",\n",
    "    \"RoA\",\n",
    "    \"LA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "x1 = [\"Faithfullness\"] * 4 + [\"Robustness\"] * 4 + [\"Complexity\"] * 4\n",
    "x2 = [\"LI\", \"GC\", \"EG\", \"LA\"] * 3\n",
    "x = [x1, x2]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], :30], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 30:51], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 51:60], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        name=\"Image\",\n",
    "        marker_color=colors[0],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], :30], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 30:51], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 51:60], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=np.concatenate(\n",
    "                (\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], :30], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 30:51], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 51:60], axis=1),\n",
    "                ),\n",
    "                axis=None,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 60:90], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 90:111], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 111:120], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        name=\"Volume\",\n",
    "        marker_color=colors[3],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 60:90], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 90:111], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 111:120], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=np.concatenate(\n",
    "                (\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 60:90], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 90:111], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 111:120], axis=1),\n",
    "                ),\n",
    "                axis=None,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 120:150], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 150:171], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 171:180], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        name=\"Point Cloud\",\n",
    "        marker_color=colors[5],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.concatenate(\n",
    "            (\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 120:150], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 150:171], axis=1), 1),\n",
    "                np.round(np.mean(df_table.iloc[[1, 6, 10, 16], 171:180], axis=1), 1),\n",
    "            ),\n",
    "            axis=None,\n",
    "        ),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=np.concatenate(\n",
    "                (\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 120:150], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 150:171], axis=1),\n",
    "                    sem(df_table.iloc[[1, 6, 10, 16], 171:180], axis=1),\n",
    "                ),\n",
    "                axis=None,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods per       Evaluation Criteria\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"Modality\", font=dict(family=\"Helvetica\", size=16, color=\"#000000\")\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=1500,\n",
    ")\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/mod_aggr_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN vs. Transformer Attribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking accross models\n",
    "arr_image = [arr_image_inet, arr_image_oct, arr_image_r45]\n",
    "arr_volume = [arr_volume_adr, arr_volume_org, arr_volume_ves]\n",
    "arr_pc = [arr_pc_coma, arr_pc_m40, arr_pc_shpn]\n",
    "arr_modalities = [arr_image, arr_volume, arr_pc]\n",
    "\n",
    "arr_ranking_transf = np.empty(\n",
    "    [3, 3, 3, 14, 20], dtype=float\n",
    ")  # modality, dataset, xai, eval\n",
    "arr_ranking_transf[:] = np.nan\n",
    "\n",
    "bup_order = [0, 1, 2, 4, 5, 7, 9, 12, 17]\n",
    "\n",
    "\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for model in range(3):\n",
    "            for eval in range(20):\n",
    "                if model == 2:\n",
    "                    ranking = np.median(\n",
    "                        arr_modalities[modality][dataset][model][:-3, eval, :], -1\n",
    "                    ).argsort()\n",
    "                else:\n",
    "                    ranking = np.median(\n",
    "                        arr_modalities[modality][dataset][model][:, eval, :], -1\n",
    "                    ).argsort()\n",
    "                # compute ranking based on median obs score\n",
    "                if eval in bup_order:\n",
    "                    ranking = ranking[\n",
    "                        ::-1\n",
    "                    ]  # reverse ranking to bottom up if larger is better\n",
    "\n",
    "                for xai in range(ranking.shape[0]):\n",
    "                    pos = (\n",
    "                        ranking.argsort()[xai] + 1\n",
    "                    )  # get rankin position of xai method (+1 so ranking starts at 1 and not 0)\n",
    "                    arr_ranking_transf[modality, dataset, model, xai, eval] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_img = np.array([[0.999, 0.9969, 0.999], [0.9535, 0.9549, 0.9567]])\n",
    "\n",
    "perf_vol = np.array(\n",
    "    [[0.8, 0.802, 0.7907], [0.9226, 0.8914, 0.84], [0.9358, 0.9162, 0.886]]\n",
    ")  # dataset, model\n",
    "\n",
    "perf_pc = np.array(\n",
    "    [[0.98, 0.9423, 0.9662], [0.8438, 0.8864, 0.8796], [0.9668, 0.9745, 0.9716]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_corr = np.empty([3, 2, 14])  # criteria, dataset, xai\n",
    "\n",
    "for dataset in range(2):\n",
    "    for xai in range(14):\n",
    "        img_corr[0, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[0, dataset + 1, :, :, :10], axis=2)[:, xai],\n",
    "                perf_img[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )\n",
    "        img_corr[1, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[0, dataset + 1, :, :, 10:17], axis=2)[\n",
    "                    :, xai\n",
    "                ],\n",
    "                perf_img[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )\n",
    "        img_corr[2, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[0, dataset + 1, :, :, 17:], axis=2)[:, xai],\n",
    "                perf_img[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_corr = np.empty([3, 3, 14])  # criteria, dataset, xai\n",
    "\n",
    "for dataset in range(3):\n",
    "    for xai in range(14):\n",
    "        vol_corr[0, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[1, dataset, :, :, :10], axis=2)[:, xai],\n",
    "                perf_vol[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )\n",
    "        vol_corr[1, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[1, dataset, :, :, 10:17], axis=2)[:, xai],\n",
    "                perf_vol[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )\n",
    "        vol_corr[2, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[1, dataset, :, :, 17:], axis=2)[:, xai],\n",
    "                perf_vol[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_corr = np.empty([3, 3, 14])  # criteria, dataset, xai\n",
    "\n",
    "for dataset in range(3):\n",
    "    for xai in range(11):\n",
    "        pc_corr[0, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[2, dataset, :, :11, :10], axis=2)[:, xai],\n",
    "                perf_pc[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )\n",
    "        pc_corr[1, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[2, dataset, :, :11, 10:17], axis=2)[:, xai],\n",
    "                perf_pc[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )\n",
    "        pc_corr[2, dataset, xai] = np.round(\n",
    "            pearsonr(\n",
    "                np.mean(arr_ranking_transf[2, dataset, :, :11, 17:], axis=2)[:, xai],\n",
    "                perf_pc[dataset],\n",
    "            )[0],\n",
    "            2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(\n",
    "    [\n",
    "        np.nanmean(img_corr, axis=(1, 2)),\n",
    "        np.nanmean(vol_corr, axis=(1, 2)),\n",
    "        np.nanmean(pc_corr, axis=(1, 2)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=np.round(\n",
    "            np.stack(\n",
    "                [\n",
    "                    np.nanmean(img_corr, axis=(1, 2)),\n",
    "                    np.nanmean(vol_corr, axis=(1, 2)),\n",
    "                    np.nanmean(pc_corr, axis=(1, 2)),\n",
    "                ]\n",
    "            ),\n",
    "            3,\n",
    "        ),\n",
    "        x=[\n",
    "            \"Faithfulness\",\n",
    "            \"Robustness\",\n",
    "            \"Complexity\",\n",
    "        ],\n",
    "        y=[\"Image\", \"Volume\", \"Point Cloud\"],\n",
    "        texttemplate=\"%{z}\",\n",
    "        colorscale=\"plasma\",\n",
    "        zmin=-0.15,\n",
    "        zmax=0.15,\n",
    "        colorbar=dict(ticks=\"outside\", thickness=9, len=1.1, tickvals=[-0.15, 0, 0.15]),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(\n",
    "        title=\"Modality\",\n",
    "        scaleanchor=\"x\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=\"Evaluation Criteria\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=16),\n",
    "    template=\"plotly_white\",\n",
    "    height=420,\n",
    "    width=415,\n",
    ")\n",
    "\n",
    "fig.write_image(\n",
    "    os.getcwd().split(\"src\")[0] + \"data/figures/heatmap_correlation.png\", scale=2\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "arr_corr_transf = np.empty(\n",
    "    [3, 3, 3, 7], dtype=float\n",
    ")  # modality, dataset, model combo, eval\n",
    "arr_corr_transf[:] = np.nan\n",
    "\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for eval in range(7):\n",
    "            arr_corr_transf[modality, dataset, 0, eval] = kendalltau(\n",
    "                arr_ranking_transf[modality, dataset, 0, :, 10 + eval],\n",
    "                arr_ranking_transf[modality, dataset, 1, :, 10 + eval],\n",
    "                nan_policy=\"omit\",\n",
    "            )[0]\n",
    "            arr_corr_transf[modality, dataset, 1, eval] = kendalltau(\n",
    "                arr_ranking_transf[modality, dataset, 0, :, 10 + eval],\n",
    "                arr_ranking_transf[modality, dataset, 2, :, 10 + eval],\n",
    "                nan_policy=\"omit\",\n",
    "            )[0]\n",
    "            arr_corr_transf[modality, dataset, 2, eval] = kendalltau(\n",
    "                arr_ranking_transf[modality, dataset, 1, :, 10 + eval],\n",
    "                arr_ranking_transf[modality, dataset, 2, :, 10 + eval],\n",
    "                nan_policy=\"omit\",\n",
    "            )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        z=np.round(np.mean(arr_corr_transf, axis=(1, 3)), 2),\n",
    "        x=[\n",
    "            \"CNN<sub>1</sub> vs. CNN<sub>2</sub>\",\n",
    "            \"CNN<sub>1</sub> vs. Transformer\",\n",
    "            \"CNN<sub>2</sub> vs. Transformer\",\n",
    "        ],\n",
    "        y=[\"Image\", \"Volume\", \"Point Cloud\"],\n",
    "        texttemplate=\"%{z}\",\n",
    "        colorscale=\"plasma\",\n",
    "        zmin=0,\n",
    "        zmax=0.6,\n",
    "        colorbar=dict(ticks=\"outside\", thickness=9, len=1.1, tickvals=[0, 0.3, 0.6]),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(\n",
    "        title=\"Modality\",\n",
    "        scaleanchor=\"x\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=\"Compared Models\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=16),\n",
    "    template=\"plotly_white\",\n",
    "    height=420,\n",
    "    width=415,\n",
    ")\n",
    "\n",
    "fig.write_image(os.getcwd().split(\"src\")[0] + \"data/figures/heatmap_rob.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_image = [arr_image_inet, arr_image_oct, arr_image_r45]\n",
    "arr_volume = [arr_volume_adr, arr_volume_org, arr_volume_ves]\n",
    "arr_pc = [arr_pc_coma, arr_pc_m40, arr_pc_shpn]\n",
    "arr_modalities = [arr_image, arr_volume, arr_pc]\n",
    "\n",
    "arr_ranking = np.empty([3, 3, 3, 14, 20], dtype=float)  # modality, dataset, xai, eval\n",
    "arr_ranking[:] = np.nan\n",
    "\n",
    "bup_order = [0, 1, 2, 4, 5, 7, 9, 12, 17]\n",
    "\n",
    "\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for eval in range(20):\n",
    "            arr_models = []\n",
    "            for model in range(3):\n",
    "                d = arr_modalities[modality][dataset][model][:, eval, :]\n",
    "                q_h = np.quantile(d, 0.975)\n",
    "                q_l = np.quantile(d, 0.025)\n",
    "\n",
    "                d = np.clip(d, q_l, q_h)\n",
    "                d_max = d.max()\n",
    "                d_min = d.min()\n",
    "                arr_models.append(NormalizeData(d, d_min, d_max))\n",
    "\n",
    "            ranking_cnn = np.median(\n",
    "                np.hstack([arr_models[0], arr_models[1]]), -1\n",
    "            ).argsort()\n",
    "            ranking_transf = np.median(arr_models[2][:-3], -1).argsort()\n",
    "            # compute ranking based on median obs score\n",
    "            if eval in bup_order:\n",
    "                ranking_cnn = ranking_cnn[\n",
    "                    ::-1\n",
    "                ]  # reverse ranking to bottom up if larger is better\n",
    "                ranking_transf = ranking_transf[::-1]\n",
    "\n",
    "            for xai in range(ranking_cnn.shape[0]):\n",
    "                pos = (\n",
    "                    ranking_cnn.argsort()[xai] + 1\n",
    "                )  # get rankin position of xai method (+1 so ranking starts at 1 and not 0)\n",
    "                arr_ranking[modality, dataset, 0, xai, eval] = pos\n",
    "\n",
    "            for xai in range(ranking_transf.shape[0]):\n",
    "                pos = ranking_transf.argsort()[xai] + 1\n",
    "                arr_ranking[modality, dataset, 1, xai, eval] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_table = []\n",
    "for model in range(3):\n",
    "    for eval in range(10):\n",
    "        for modality in range(1):\n",
    "            for dataset in range(3):\n",
    "                arr_col_val = []\n",
    "                for xai in range(14):\n",
    "                    if modality == 2 and xai == 6:\n",
    "                        arr_col_val = arr_col_val + [np.nan, np.nan, np.nan]\n",
    "                    if modality == 2 and xai == 11:\n",
    "                        break\n",
    "                    val = arr_ranking[modality, dataset, model, xai, eval]\n",
    "                    arr_col_val.append(val)\n",
    "                arr_table.append(arr_col_val)\n",
    "\n",
    "df_table = pd.DataFrame(arr_table).transpose()\n",
    "df_table.index = [\n",
    "    \"OC\",\n",
    "    \"LI\",\n",
    "    \"KS\",\n",
    "    \"VG\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_mean = []\n",
    "diff_se = []\n",
    "for i in range(14):\n",
    "    diff_1 = df_table.iloc[i, 60:].to_numpy() - df_table.iloc[i, :60].to_numpy()\n",
    "    diff_mean.append(np.nanmean(diff_1))\n",
    "    diff_se.append(sem(np.abs(diff_1), nan_policy=\"omit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "x = [\n",
    "    \"OC\",\n",
    "    \"LI\",\n",
    "    \"KS\",\n",
    "    \"VG\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(diff_mean, 2),\n",
    "        name=\"Faithfulness\",\n",
    "        marker_color=colors[0],\n",
    "        error_y=dict(type=\"data\", array=diff_se),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4, range=[-2.5, 2.5])\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(\n",
    "        title=\"Avg. Difference in Rank\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=\"Attribution Methods\",\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    "    legend_title=dict(\n",
    "        text=\"Evaluation Criteria\",\n",
    "        font=dict(family=\"Helvetica\", size=16, color=\"#000000\"),\n",
    "    ),\n",
    "    template=\"plotly_white\",\n",
    "    height=500,\n",
    "    width=900,\n",
    ")\n",
    "\n",
    "for i in range(14):\n",
    "    t1 = stats.ttest_1samp(\n",
    "        a=df_table.iloc[i, 60:].to_numpy() - df_table.iloc[i, :60].to_numpy(),\n",
    "        popmean=-0.1,\n",
    "        nan_policy=\"omit\",\n",
    "    )[1]\n",
    "    fig = add_p_value_annotation(\n",
    "        fig,\n",
    "        array_columns=[[i, i]],\n",
    "        p_value=[t1],\n",
    "        _format=dict(interline=0.05, text_height=1.05, color=\"black\"),\n",
    "    )\n",
    "\n",
    "# fig.write_image(os.getcwd() + \"/data/figures/diff_plot.png\", scale=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Ranking\n",
    "arr_image = [arr_image_inet, arr_image_oct, arr_image_r45]\n",
    "arr_volume = [arr_volume_adr, arr_volume_org, arr_volume_ves]\n",
    "arr_pc = [arr_pc_coma, arr_pc_m40, arr_pc_shpn]\n",
    "arr_modalities = [arr_image, arr_volume, arr_pc]\n",
    "\n",
    "arr_ranking = np.empty(\n",
    "    [3, 3, 3, 14, 20], dtype=float\n",
    ")  # modality, dataset, model, xai, eval\n",
    "arr_ranking[:] = np.nan\n",
    "\n",
    "bup_order = [0, 1, 2, 4, 5, 7, 9, 12, 17]\n",
    "\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for model in range(3):\n",
    "            for xai in range(11 if modality == 2 else 14):\n",
    "                for eval in range(20):\n",
    "                    ranking = np.median(\n",
    "                        arr_modalities[modality][dataset][model][\n",
    "                            : 11 if modality == 2 else 14, eval, :\n",
    "                        ],\n",
    "                        -1,\n",
    "                    ).argsort()  # compute ranking based on median obs score\n",
    "\n",
    "                    if eval in bup_order:\n",
    "                        ranking = ranking[\n",
    "                            ::-1\n",
    "                        ]  # reverse ranking to bottom up if larger is better\n",
    "\n",
    "                    pos = (\n",
    "                        ranking.argsort()[xai] + 1\n",
    "                    )  # get rankin position of xai method (+1 so ranking starts at 1 and not 0)\n",
    "                    arr_ranking[modality, dataset, model, xai, eval] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_diff_01 = np.empty([3, 3, 14, 20], dtype=float)\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for xai in range(14):\n",
    "            for eval in range(20):\n",
    "                arr_diff_01[modality, dataset, xai, eval] = np.abs(\n",
    "                    arr_ranking[modality, dataset, 0, xai, eval]\n",
    "                    - arr_ranking[modality, dataset, 1, xai, eval]\n",
    "                )\n",
    "\n",
    "arr_diff_02 = np.empty([3, 3, 14, 20], dtype=float)\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for xai in range(14):\n",
    "            for eval in range(20):\n",
    "                arr_diff_02[modality, dataset, xai, eval] = np.abs(\n",
    "                    arr_ranking[modality, dataset, 2, xai, eval]\n",
    "                    - arr_ranking[modality, dataset, 0, xai, eval]\n",
    "                )\n",
    "\n",
    "arr_diff_12 = np.empty([3, 3, 14, 20], dtype=float)\n",
    "for modality in range(3):\n",
    "    for dataset in range(3):\n",
    "        for xai in range(14):\n",
    "            for eval in range(20):\n",
    "                arr_diff_12[modality, dataset, xai, eval] = np.abs(\n",
    "                    arr_ranking[modality, dataset, 2, xai, eval]\n",
    "                    - arr_ranking[modality, dataset, 1, xai, eval]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_sum_01 = np.concatenate(\n",
    "    [\n",
    "        (arr_diff_01[0, :, :6, :] + arr_diff_01[1, :, :6, :] + arr_diff_01[2, :, :6, :])\n",
    "        / 3,\n",
    "        (arr_diff_01[0, :, 6:9, :] + arr_diff_01[1, :, 6:9, :]) / 2,\n",
    "        (\n",
    "            arr_diff_01[0, :, 9:, :]\n",
    "            + arr_diff_01[1, :, 9:, :]\n",
    "            + arr_diff_01[2, :, 6:11, :]\n",
    "        )\n",
    "        / 3,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "arr_sum_02 = np.concatenate(\n",
    "    [\n",
    "        (arr_diff_02[0, :, :6, :] + arr_diff_02[1, :, :6, :] + arr_diff_02[2, :, :6, :])\n",
    "        / 3,\n",
    "        (arr_diff_02[0, :, 6:9, :] + arr_diff_02[1, :, 6:9, :]) / 2,\n",
    "        (\n",
    "            arr_diff_02[0, :, 9:, :]\n",
    "            + arr_diff_02[1, :, 9:, :]\n",
    "            + arr_diff_02[2, :, 6:11, :]\n",
    "        )\n",
    "        / 3,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "arr_sum_12 = np.concatenate(\n",
    "    [\n",
    "        (arr_diff_01[0, :, :6, :] + arr_diff_01[1, :, :6, :] + arr_diff_01[2, :, :6, :])\n",
    "        / 3,\n",
    "        (arr_diff_12[0, :, 6:9, :] + arr_diff_12[1, :, 6:9, :]) / 2,\n",
    "        (\n",
    "            arr_diff_12[0, :, 9:, :]\n",
    "            + arr_diff_12[1, :, 9:, :]\n",
    "            + arr_diff_12[2, :, 6:11, :]\n",
    "        )\n",
    "        / 3,\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "x = [\n",
    "    \"OC\",\n",
    "    \"LI\",\n",
    "    \"KS\",\n",
    "    \"VG\",\n",
    "    \"IxG\",\n",
    "    \"GB\",\n",
    "    \"GC\",\n",
    "    \"SC\",\n",
    "    \"C+\",\n",
    "    \"IG\",\n",
    "    \"EG\",\n",
    "    \"DL\",\n",
    "    \"DLS\",\n",
    "    \"LRP\",\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.nanmean(arr_sum_01, axis=(0, 2)), 1),\n",
    "        name=\"|CNN<sub>1</sub> - CNN<sub>2</sub>|\",\n",
    "        marker_color=colors[0],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(arr_sum_01, axis=(0, 2)), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=[np.round(sem(arr_sum_01[:, i, :].flatten()), 2) for i in range(14)],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.nanmean(arr_sum_02, axis=(0, 2)), 1),\n",
    "        name=\"|Transformer - CNN<sub>1</sub>|\",\n",
    "        marker_color=colors[2],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(arr_sum_02, axis=(0, 2)), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=[np.round(sem(arr_sum_02[:, i, :].flatten()), 2) for i in range(14)],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=np.round(np.nanmean(arr_sum_12, axis=(0, 2)), 1),\n",
    "        name=\"|Transformer - CNN<sub>2</sub>|\",\n",
    "        marker_color=colors[5],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=np.round(np.mean(arr_sum_12, axis=(0, 2)), 1),\n",
    "        error_y=dict(\n",
    "            type=\"data\",\n",
    "            array=[np.round(sem(arr_sum_12[:, i, :].flatten()), 2) for i in range(14)],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank Distance\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=16),\n",
    "    legend_title=dict(\n",
    "        text=\"Difference\",\n",
    "        font=dict(family=\"Helvetica\", size=16, color=\"#000000\"),\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=1500,\n",
    ")\n",
    "\n",
    "fig.write_image(\n",
    "    os.getcwd().split(\"src\")[0] + \"data/figures/bar_archdiff_total.png\", scale=2\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "colors = px.colors.qualitative.G10\n",
    "fig = go.Figure()\n",
    "\n",
    "x = [\n",
    "    [\n",
    "        \"Image\",\n",
    "        \"Image\",\n",
    "        \"Image\",\n",
    "        \"Volume\",\n",
    "        \"Volume\",\n",
    "        \"Volume\",\n",
    "        \"Image\",\n",
    "        \"Volume\",\n",
    "        \"Point Cloud\",\n",
    "    ],\n",
    "    [\n",
    "        \"GC\",\n",
    "        \"SC\",\n",
    "        \"C+\",\n",
    "        \"GC\",\n",
    "        \"SC\",\n",
    "        \"C+\",\n",
    "        \"LRP\",\n",
    "        \"LRP\",\n",
    "        \"LRP\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "trace_01 = [\n",
    "    *np.mean(arr_diff_01[0], axis=(0, 2))[6:9].tolist(),\n",
    "    *np.mean(arr_diff_01[1], axis=(0, 2))[6:9].tolist(),\n",
    "    np.mean(arr_diff_01[0], axis=(0, 2))[13],\n",
    "    np.mean(arr_diff_01[1], axis=(0, 2))[13],\n",
    "    np.mean(arr_diff_01[2], axis=(0, 2))[10],\n",
    "]\n",
    "\n",
    "trace_01_sem = [\n",
    "    sem(arr_diff_01[0, :, 6, :].flatten()),\n",
    "    sem(arr_diff_01[0, :, 7, :].flatten()),\n",
    "    sem(arr_diff_01[0, :, 8, :].flatten()),\n",
    "    sem(arr_diff_01[1, :, 6, :].flatten()),\n",
    "    sem(arr_diff_01[1, :, 7, :].flatten()),\n",
    "    sem(arr_diff_01[1, :, 8, :].flatten()),\n",
    "    sem(arr_diff_01[0, :, 13, :].flatten()),\n",
    "    sem(arr_diff_01[1, :, 13, :].flatten()),\n",
    "    sem(arr_diff_01[2, :, 10, :].flatten()),\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=trace_01,\n",
    "        name=\"|CNN<sub>1</sub> - CNN<sub>2</sub>|\",\n",
    "        marker_color=colors[0],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=[round(i, 1) for i in trace_01],\n",
    "        error_y=dict(type=\"data\", array=trace_01_sem),\n",
    "    )\n",
    ")\n",
    "\n",
    "trace_02 = [\n",
    "    *np.mean(arr_diff_02[0], axis=(0, 2))[6:9].tolist(),\n",
    "    *np.mean(arr_diff_02[1], axis=(0, 2))[6:9].tolist(),\n",
    "    np.mean(arr_diff_02[0], axis=(0, 2))[13],\n",
    "    np.mean(arr_diff_02[1], axis=(0, 2))[13],\n",
    "    np.mean(arr_diff_02[2], axis=(0, 2))[10],\n",
    "]\n",
    "\n",
    "trace_02_sem = [\n",
    "    sem(arr_diff_02[0, :, 6, :].flatten()),\n",
    "    sem(arr_diff_02[0, :, 7, :].flatten()),\n",
    "    sem(arr_diff_02[0, :, 8, :].flatten()),\n",
    "    sem(arr_diff_02[1, :, 6, :].flatten()),\n",
    "    sem(arr_diff_02[1, :, 7, :].flatten()),\n",
    "    sem(arr_diff_02[1, :, 8, :].flatten()),\n",
    "    sem(arr_diff_02[0, :, 13, :].flatten()),\n",
    "    sem(arr_diff_02[1, :, 13, :].flatten()),\n",
    "    sem(arr_diff_02[2, :, 10, :].flatten()),\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=trace_02,\n",
    "        name=\"|Transformer - CNN<sub>1</sub>|\",\n",
    "        marker_color=colors[2],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=[round(i, 1) for i in trace_02],\n",
    "        error_y=dict(type=\"data\", array=trace_02_sem),\n",
    "    )\n",
    ")\n",
    "\n",
    "trace_12 = [\n",
    "    *np.mean(arr_diff_12[0], axis=(0, 2))[6:9].tolist(),\n",
    "    *np.mean(arr_diff_12[1], axis=(0, 2))[6:9].tolist(),\n",
    "    np.mean(arr_diff_12[0], axis=(0, 2))[13],\n",
    "    np.mean(arr_diff_12[1], axis=(0, 2))[13],\n",
    "    np.mean(arr_diff_12[2], axis=(0, 2))[10],\n",
    "]\n",
    "\n",
    "trace_12_sem = [\n",
    "    sem(arr_diff_12[0, :, 6, :].flatten()),\n",
    "    sem(arr_diff_12[0, :, 7, :].flatten()),\n",
    "    sem(arr_diff_12[0, :, 8, :].flatten()),\n",
    "    sem(arr_diff_12[1, :, 6, :].flatten()),\n",
    "    sem(arr_diff_12[1, :, 7, :].flatten()),\n",
    "    sem(arr_diff_12[1, :, 8, :].flatten()),\n",
    "    sem(arr_diff_12[0, :, 13, :].flatten()),\n",
    "    sem(arr_diff_12[1, :, 13, :].flatten()),\n",
    "    sem(arr_diff_12[2, :, 10, :].flatten()),\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=trace_12,\n",
    "        name=\"|Transformer - CNN<sub>2</sub> |\",\n",
    "        marker_color=colors[5],\n",
    "        textposition=\"inside\",\n",
    "        insidetextanchor=\"start\",\n",
    "        text=[round(i, 1) for i in trace_12],\n",
    "        error_y=dict(type=\"data\", array=trace_12_sem),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=np.mean(np.stack((arr_diff_01[0], arr_diff_02[0], arr_diff_12[0]), 0)),\n",
    "    x0=0,\n",
    "    x1=4 / 9,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"#000000\",\n",
    "    line_width=3,\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=np.mean(np.stack((arr_diff_01[1], arr_diff_02[1], arr_diff_12[1]), 0)),\n",
    "    x0=4 / 9,\n",
    "    x1=8 / 9,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"#000000\",\n",
    "    line_width=3,\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=np.nanmean(np.stack((arr_diff_01[2], arr_diff_02[2], arr_diff_12[2]), 0)),\n",
    "    x0=8 / 9,\n",
    "    x1=9 / 9,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"#000000\",\n",
    "    line_width=3,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(zerolinewidth=4)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"XAI Methods\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Rank Distance\",\n",
    "        titlefont_size=18,\n",
    "        tickfont_size=16,\n",
    "    ),\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=16),\n",
    "    legend_title=dict(\n",
    "        text=\"Model Architectures\",\n",
    "        font=dict(family=\"Helvetica\", size=16, color=\"#000000\"),\n",
    "    ),\n",
    "    barmode=\"group\",\n",
    "    template=\"plotly_white\",\n",
    "    bargap=0.15,  # gap between bars of adjacent location coordinates.\n",
    "    bargroupgap=0.05,  # gap between bars of the same location coordinate.\n",
    "    height=500,\n",
    "    width=1500,\n",
    ")\n",
    "\n",
    "fig.write_image(os.getcwd().split(\"src\")[0] + \"data/figures/bar_archdiff.png\", scale=2)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
